# Policy and säkerhet as code in detalj ![Policy and säkerhet as code](images/diagram_12_kapitel11.png) *Policy as Code representerar nästa evolutionssteg within Architecture as Code where säkerhet, compliance and governance is automated through programmerbara regler. Diagrammet visar integreringen of policy enforcement in the entire utvecklingslivscykeln from design to produktion.* ## Introduktion and kontextualisering in en värld where Swedish organizations manage all mer komplexa digital infrastrukturer as well asidigt that regulatoriska requirements skärps kontinuerligt, hofe Policy as Code (PaC) framträtt that en oumbärlig disciplin within Infrastructure as Code (Architecture as Code). While [chapter 10 om säkerhet](10_sakerhet.md) introducerade fundamental security principles, tar This chapter ett djupt dyk in den advanced implementationen of policy-drivna säkerhetslösningar and introducerar The reader to Open Security Controls Assessment Language (OSCAL) - en revolutionerande standard for säkerhetshantering. Det traditional paradigmet for säkerhets- and compliance-hantering characterized of manual processes, statiska dokumentation and reaktiva strategier. This approach skapar flaskhalsar in moderna utvecklingscykler where infrastrukturändringar sker flera gånger dagligen through automated CI/CD-pipelines. Swedish organizations, that traditionalt been foregångare within säkerhet and compliance, står nu infor utmaningen to digitalisera and automate these processes without to kompromissa with säkerhetsnivån. Policy as Code adresserar this utmaning through to transformera säkerhet from en extern kontrollmekanism to en integrerad del of utvecklingsprocessen. Through to uttrycka säkerhetskrof, compliance rules and governance-policies as code uppnås samma fordelar that Infrastructure as Code erbjuder: versionskontroll, testbarhet, återanvändbarhet, and konsistent deployment over miljöer and team. In den Swedish kontexten möter organizations en komplex regulatorisk miljö that includes EU:s allmänna data protectionsforordning (GDPR), Myndigheten for samhällsskydd and beredskaps (MSB) säkerhetskrof for kritisk infrastructure, NIS2-direktivet, and branschspecific regulations within finansiella tjänster, vård and offentlig sektor. Traditional compliance-approaches baserade on manual kontroller and document-based policies is not only ineffektiva without också riskfyllda in dynamiska molnmiljöer. This chapter utforskar how Policy as Code, forstärkt with OSCAL-standarder, enables for Swedish organizations to uppnå unprecedented nivåer of säkerhetsArchitecture as Code-automation and compliance-monitoring. We will to duringsöka verkliga Architecture as Code-implementationspattern, analysera case studies from Swedish organizations, and ge The reader konkreta tools for to implement enterprise-grade policy management. ## The evolution of säkerhetshantering within Infrastructure as Code Architecture as Code-principlesna within This område Säkerhetshantering within Infrastructure as Code hofe throughgått en betydande evolution from ad-hoc skript and manual checklistor to sofistikerade policy engines and automated compliance frameworks. This evolution can delas in fyra distinkta faser, var and en with their egna karakteristiska challenges and opportunities. **Fas 1: Manual Säkerhetsvalidering (2010-2015)** infrastrukturens barndom utfordes säkerhetsvalidering primärt through manual processes. Säkerhetsteam granskade infrastrukturkonfigurationer after deployment, often veckор or månader after to resurserna blev produktiva. This reaktiva approach ledde to upptäckten of säkerhetsproblem långt after to de kunde orsaka skada. Swedish organizations, with their strikta säkerhetskrof, var särskilt utsatta for de ineffektiviteter that this approach withforde. Utmaningarna var många: inkonsistent toämpning of security policies, långa feedback-loopar between utveckling and säkerhet, and begränsad skalbarhet när organizations växte and antalet infrastrukturresurser ökade exponentiellt. Dokumentation blev snabbt foråldrad, and kunskapsoverforing between team var problematisk. **Fas 2: Scriptbaserad Architecture as Code-automation (2015-2018)** När organizations började inse begränsningarna with manual processes började de utveckla skript for to automate säkerhetsvalidering. Python-skript, Bash-scripts and powershell-moduler utvecklades for to kontrollera infrastrukturkonfigurationer mot companiesspolicies. This approach möjliggjorde snabbare validering but saknade standardisering and var svår to duringhålla. Swedish utvecklingsteam började experimentera with custom security validation scripts that integrerades in CI/CD-pipelines. These early adopters upptäckte både opportunitiesna and begränsningarna with scriptbaserad automation: while automation improvede hastigheten betydligt, blev maintenance of hundratals specialiserade scripts en börda in sig själv. **Fas 3: Policy Engine Integration (2018-2021)** Introduktionen of dedikerade policy engines that Open Policy Agent (OPA) markerade en vändpunkt in utvecklingen of säkerhetsautomatisering. These tools erbjöd standardiserade sätt to uttrycka and utvärdera policies, vilket möjliggjorde separation of policy logic from Architecture as Code-implementation details. Kubernetes adoption in Swedish organizations drev utvecklingen of sofistikerade admission controllers and policy enforcement points. Gatekeeper, baserat on OPA, blev snabbt de facto standarden for Kubernetes policy enforcement. Swedish enterprise-organizations började utveckla comprehensive policy libraries that täckte all from basic security hygiene to complex compliance requirements. **Fas 4: Comprehensive Policy Frameworks (2021-nu)** Dagens generation of policy as code platforms integrerar djupt with the entire utvecklingslivscykeln, from design-time validation to runtime monitoring and automated rewithiation. OSCAL (Open Security Controls Assessment Language) hofe framträtt that en game-changing standard that enables interoperabilitet between olika säkerhetsverktyg and standardiserad representation of säkerhetskontroller. Swedish organizations is nu in forfronten of to adoptера comprehensive policy frameworks that kombinerar policy as code with continuous compliance monitoring, automated risk assessment and adaptive security controls. This evolution hofe enabled for organizations to uppnå regulatory compliance with unprecedented precision and effektivitet. ## Open Policy Agent (OPA) and Rego: Grunden for policy-driven säkerhet Open Policy Agent hofe etablerats that de facto standarden for policy as code implementation through sin flexibla arkitektur and kraftfulla deklarativa policy-språk Rego. OPA:s success ligger in dess formåga to separera policy logic from application logic, vilket enables centraliserad policy management as well asidigt that utvecklingsteam behåller autonomi over their applikationer and infrastrukturer. Rego-språket representerar en paradigm shift from imperativ to deklarativ policy definition. Istället for to specificera "how" något should göras, fokuserar Rego on "vad" that should uppnås. This approach resulterar in policies that is mer läsbara, testbara and duringsustainablea jämfort with traditional script-baserade lösningar. For Swedish organizations that must nofigera komplex regulatorisk miljö, erbjuder OPA and Rego en kraftfull platform for to implement all from basic säkerhetshygien to sophisticated compliance frameworks. Policy-developers can skapa modulära, återanvändbara bibliotek that täcker common säkerhetspatterns, regulatory requirements and organizational standards. ### Arkitekturell foundation for enterprise policy management OPA:s arkitektur builds on flera nyckelprinciples that gör det särskilt lämpat for enterprise-environments: **Decouplad Policy Evaluation**: OPA agerar that en policy evaluation engine that tar emot data and policies that input and producerar decisions that output. This separation toåter samma policy logic to appliceras over olika systems and environments without modification. **Pull vs Push Policy Distribution**: OPA stödjer både pull-baserad policy distribution (where agents hämtar policies from centrala repositories) and push-baserad distribution (where policies distribueras aktivt to agents). Swedish organizations with strikta säkerhetskrof foredrar often pull-baserade approaches for bättre auditability and control. **Bundle-baserad Policy Packaging**: Policies and data can paketeras that bundles that includes dependencies, metadata and signatures. This enables atomic policy updates and rollback capabilities that is kritiska for production environments. ### Avancerad Rego-programmering for Swedish compliance-requirements ```rego # Policies/advanced_swedish_compliance.rego package sweden.enterprise.security import rego.v1 # ======================================== # GDPR Article 32 - Advanced implementation # ======================================== # Komprehensiv krypteringsvalidering that manage olika AWS-services encryption_compliant[resource] { resource := input.reSources[_] resource.type in encryption_required_services encryption_methods := get_encryption_status(resource) encryption_validation := validate_encryption_strength(encryption_methods) encryption_validation.compliant == true } encryption_required_services := { "aws_s3_bucket", "aws_rds_instance", "aws_rds_cluster", "aws_ebs_volume", "aws_efs_file_system", "aws_dynamodb_table", "aws_redshift_cluster", "aws_elasticsearch_domain", "aws_kinesis_stream", "aws_sqs_queue", "aws_sns_topic" } # Avancerad krypteringsvalidering with stöd for olika encryption methods get_encryption_status(resource) := result { resource.type == "aws_s3_bucket" result := { "at_rest": has_s3_encryption(resource), "in_transit": has_s3_ssl_policy(resource), "key_management": get_s3_key_management(resource) } } get_encryption_status(resource) := result { resource.type == "aws_rds_instance" result := { "at_rest": resource.attributes.storage_encrypted, "in_transit": resource.attributes.force_ssl, "key_management": get_rds_kms_config(resource) } } # Validera krypteringsstyrka according to Swedish säkerhetskrof validate_encryption_strength(encryption) := result { # Kontrollera to både at-rest and in-transit encryption is aktiverat encryption.at_rest == true encryption.in_transit == true # Validera key management practices key_validation := validate_key_management(encryption.key_management) result := { "compliant": key_validation.approved, "strength_level": key_validation.strength, "recombutdations": key_validation.recombutdations } } validate_key_management(kms_config) := result { # AWS KMS Customer Managed Keys rekombutderas for Swedish organizations kms_config.type == "customer_managed" kms_config.key_rotation_enabled == true kms_config.multi_region_key == false # Datasuveränitet result := { "approved": true, "strength": "high", "recombutdations": [] } } validate_key_management(kms_config) := result { # AWS Managed Keys acceptabelt but with rekombutdationer kms_config.type == "aws_managed" result := { "approved": true, "strength": "withium", "recombutdations": [ "Överväg customer managed keys for improved kontroll", "implement key rotation policies" ] } } # ======================================== # MSB Säkerhetskrof - Nätverkssegmentering # ======================================== # Sofistikerad nätverksvalidering that manage complex network topologies network_security_compliant[violation] { resource := input.reSources[_] resource.type == "aws_security_group" violations := evaluate_network_security(resource) violation := violations[_] violation.severity in ["critical", "high"] } evaluate_network_security(security_group) := violations { violations := array.concat( evaluate_ingress_rules(security_group), evaluate_egress_rules(security_group) ) } evaluate_ingress_rules(sg) := violations { violations := [v | rule := sg.attributes.ingress[_] violation := check_ingress_rule(rule, sg.attributes.name) violation != null v := violation ] } check_ingress_rule(rule, sg_name) := violation { # Kritisk violation for öppna administrativa portar rule.cidr_blocks[_] == "0.0.0.0/0" rule.from_port in administrative_ports violation := { "type": "critical_port_exposure", "severity": "critical", "port": rule.from_port, "security_group": sg_name, "message": sprintf("Administrativ port %v exponerad mot internet", [rule.from_port]), "rewithiation": "Begränsa access to specific management networks", "msb_requirement": "Säkerhetskrof 3.2.1 - Nätverkssegmentering" } } check_ingress_rule(rule, sg_name) := violation { # High violation for icke-standard portar öppna mot internet rule.cidr_blocks[_] == "0.0.0.0/0" not rule.from_port in allowed_public_ports not rule.from_port in administrative_ports violation := { "type": "non_standard_port_exposure", "severity": "high", "port": rule.from_port, "security_group": sg_name, "message": sprintf("Icke-standard port %v exponerad mot internet", [rule.from_port]), "rewithiation": "Validera business requirement and begränsa access", "msb_requirement": "Säkerhetskrof 3.2.2 - Minimal exponering" } } administrative_ports := {22, 3389, 5432, 3306, 1433, 27017, 6379, 9200, 5601} allowed_public_ports := {80, 443} # ======================================== # Datasuveränitet and GDPR Compliance # ======================================== data_sovereignty_compliant[resource] { resource := input.reSources[_] resource.type in data_storage_services # Kontrollera dataklassificering classification := get_data_classification(resource) # Validera region placement baserat on dataklassificering region_compliance := validate_region_placement(resource, classification) region_compliance.compliant == true } data_storage_services := { "aws_s3_bucket", "aws_rds_instance", "aws_rds_cluster", "aws_dynamodb_table", "aws_elasticsearch_domain", "aws_redshift_cluster", "aws_efs_file_system" } get_data_classification(resource) := classification { # Prioritera explicit tagging classification := resource.attributes.tags["DataClassification"] classification != null } get_data_classification(resource) := "personal" { # Infer from resource naming patterns contains(lower(resource.attributes.name), "personal") } get_data_classification(resource) := "personal" { # Infer from database patterns resource.type in ["aws_rds_instance", "aws_rds_cluster"] database_indicators := {"user", "customer", "personal", "gdpr", "pii"} thate indicator in database_indicators contains(lower(resource.attributes.identifier), indicator) } get_data_classification(resource) := "internal" { # Default for oklassificerad data true } validate_region_placement(resource, classification) := result { # Persondata must lagras within EU classification == "personal" resource_region := get_resource_region(resource) eu_regions := {"eu-north-1", "eu-west-1", "eu-west-2", "eu-west-3", "eu-central-1", "eu-south-1"} resource_region in eu_regions result := { "compliant": true, "region": resource_region, "classification": classification, "requirement": "GDPR Artikel 44-49 - Överforingar to tredje land" } } validate_region_placement(resource, classification) := result { # Persondata in icke-EU region classification == "personal" resource_region := get_resource_region(resource) eu_regions := {"eu-north-1", "eu-west-1", "eu-west-2", "eu-west-3", "eu-central-1", "eu-south-1"} not resource_region in eu_regions result := { "compliant": false, "region": resource_region, "classification": classification, "violation_type": "data_sovereignty", "severity": "critical", "message": sprintf("Persondata lagras in region %v withoutfor EU", [resource_region]), "rewithiation": "Flytta resurs to EU-region or implement adequacy decision framework", "requirement": "GDPR Artikel 44-49 - Överforingar to tredje land" } } get_resource_region(resource) := region { # Explicit region setting region := resource.attributes.region region != null } get_resource_region(resource) := region { # Infer from ofailability zone az := resource.attributes.ofailability_zone region := substring(az, 0, count(az) - 1) } get_resource_region(resource) := "unknown" { # Fallback for reSources without explicit region true } # ======================================== # Comprehensive Compliance Assessment # ======================================== compliance_assessment := result { # Samla all compliance violations encryption_violations := [v | resource := input.reSources[_] not encryption_compliant[resource] v := create_encryption_violation(resource) ] network_violations := [v | violation := network_security_compliant[_] v := violation ] sovereignty_violations := [v | resource := input.reSources[_] not data_sovereignty_compliant[resource] v := create_sovereignty_violation(resource) ] all_violations := array.concat( array.concat(encryption_violations, network_violations), sovereignty_violations ) # Beräkna compliance score score := calculate_compliance_score(all_violations) result := { "overall_score": score, "total_violations": count(all_violations), "critical_violations": count([v | v := all_violations[_]; v.severity == "critical"]), "high_violations": count([v | v := all_violations[_]; v.severity == "high"]), "withium_violations": count([v | v := all_violations[_]; v.severity == "withium"]), "violations": all_violations, "recombutdations": generate_recombutdations(all_violations), "regulatory_compliance": { "gdpr": assess_gdpr_compliance(all_violations), "msb": assess_msb_compliance(all_violations), "iso27001": assess_iso_compliance(all_violations) } } } calculate_compliance_score(violations) := score { violation_penalty := sum([penalty | violation := violations[_] penalty := severity_penalty[violation.severity] ]) max_score := 100 score := math.max(0, max_score - violation_penalty) } severity_penalty := { "critical": 25, "high": 15, "withium": 10, "low": 5 } generate_recombutdations(violations) := recombutdations { violation_types := {v.type | v := violations[_]} recombutdations := [rec | violation_type := violation_types[_] rec := recombutdation_mapping[violation_type] ] } recombutdation_mapping := { "encryption_required": "implement enterprise encryption standards with customer managed KMS keys", "critical_port_exposure": "implement bastion hosts or AWS Systems Manager for administrativ access", "data_sovereignty": "Skapa region-specific Terraform providers for automatisk compliance", "resource_tagging": "implement obligatorisk tagging through resource policies" } ``` ### Integration with Swedish enterprise-miljöer for Swedish organizations that opererar within regulated industries requires OPA-implementation often integration with befintliga säkerhetssystem and compliance frameworks. This includes integration with SIEM-system for audit logging, identity providers for policy authorization and enterprise monitoring systems for real-time alerting. Enterprise-grade OPA deployments requires också considerations kring high ofailability, performance optimization and secure policy distribution. Swedish organizations with kritisk infrastructure must säkerställa to policy evaluation not blir en single point of failure that can onverka business operations. ## OSCAL: Open Security Controls Assessment Language - Revolutionerande säkerhetsstandardisering Open Security Controls Assessment Language (OSCAL) representerar en paradigmskifte within säkerhetshantering and compliance-automation. Utvecklad of NIST (National Institute of Standards and Technology), erbjuder OSCAL en standardiserad approach for to representera, hantera and automate säkerhetskontroller and assessment-processes. For Swedish organizations that must nofigera komplex regulatorisk miljö as well asidigt that de implementerar Infrastructure as Code, utgör OSCAL en game-changing teknik that enables unprecedented automation and interoperabilitet. OSCAL adresserar en fundamental utmaning within enterprise säkerhetshantering: fragmenteringen of säkerhetskontroller, assessment-processes and compliance-frameworks. Traditionellt hofe organizations been tvungna to hantera múltipla, inkompatibla säkerhetsstandarder (ISO 27001, NIST Cybersecurity Framework, SOC 2, GDPR, etc.) through separata system and processes. OSCAL enables en unified approach where säkerhetskontroller can uttryckas, mappas and is automated through en gebutsam meta-language. For Architecture as Code-practitioners representerar OSCAL möjligheten to integrera säkerhetskontroller direkt in utvecklingsprocessen through machine-readable formats that can valideras, testats and deployeras tosammans with Architecture as Code. This skapar en seamless integration between security governance and architecture automation that tidigare been tekniskt omöjlig to uppnå. ### OSCAL-arkitektur and komponenter OSCAL-the architecture builds on en hierarkisk struktur of sammanlänkade modor that tosammans representerar the entire lifecycle for säkerhetskontroller from definition to implementation and assessment. Varje OSCAL-modell tjänar ett specifikt purpose but is designad for seamless interoperabilitet with andra modor in ecosystemet. **Catalog Model**: Utgör foundation for OSCAL-ecosystemet through to definiera collections of säkerhetskontroller. Catalog-modellen enables standardiserad representation of kontrollers from olika frameworks (NIST SP 800-53, ISO 27001, CIS Controls, etc.) in ett unified format. For Swedish organizations enables This representation of MSB:s säkerhetskrof, GDPR-kontroller and branschspecific regulations in samma technical framework. **Profile Model**: Representerar customized selections and configurations of säkerhetskontroller from en or flera catalogs. Profiles enables organizations to skapa tailored säkerhetskrof baserat on risk tolerance, regulatory requirements and business context. Swedish finansiella institutioner can for example skapa profiles that kombinerar GDPR-requirements with Finansinspektionens säkerhetskrof and PCI DSS-standards. **Component Definition Model**: Dokumenterar how specific system komponenter (software, hardware, services) implementerar säkerhetskontroller. This modell skapar critical linking between abstrakt kontrolldefinitioner and konkret implementation details. In Infrastructure as Code-kontexten representerar component definitions how specific Terraform modules, Kubernetes deployments or AWS services implementerar required säkerhetskontroller. **System Security Plan (SSP) Model**: Beskriver comprehensive säkerhetsimplementation for ett specifikt system, including how säkerhetskontroller is implementerade, who ansvarar for varje kontroll and how kontrollers monitoras and maintainas. SSP-modellen enables automated generation of säkerhetsdokumentation direkt from Infrastructure as Code definitions. **Assessment Plan and Assessment Results Models**: Definierar how säkerhetskontroller should assessas and dokumenterar resultaten of these assessments. These modor enables automated compliance testing and continuous monitoring of säkerhetskontroller through integration with CI/CD pipelines. **Plan of Action and Milestones (POA&M) Model**: Hanterar rewithiation planning and tracking for identified säkerhetsgap. POA&M-modellen enables systematic approach to säkerhetsforbättringar and can integreras with project management tools for comprehensive risk management. ### Praktisk OSCAL-implementation for Swedish organizations implementation of OSCAL in Swedish enterprise-miljöer requires careful planning and systematic approach that respekterar befintliga säkerhetsprocesses as well asidigt that moderna automation capabilities introduceras gradvist. ```json { "catalog": { "uuid": "12345678-1234-5678-9abc-123456789012", "metadata": { "title": "Swedish Enterprise Säkerhetskontroller", "published": "2024-01-15T10:00:00Z", "last-modified": "2024-01-15T10:00:00Z", "version": "1.0", "oscal-version": "1.1.2", "props": [ { "name": "organization", "value": "Swedish Myndigheten for Samhällsskydd and Beredskap" }, { "name": "jurisdiction", "value": "Sweden" } ] }, "groups": [ { "id": "gdpr-controls", "title": "GDPR Säkerhetskontroller", "props": [ { "name": "label", "value": "GDPR" } ], "controls": [ { "id": "gdpr-art32-1", "title": "Säkerhet in behandlingen - Kryptering", "params": [ { "id": "gdpr-art32-1_prm1", "label": "Krypteringsstandard", "values": ["AES-256", "RSA-2048"] }, { "id": "gdpr-art32-1_prm2", "label": "Nyckelhantering", "values": ["HSM", "AWS KMS Customer Managed"] } ], "props": [ { "name": "label", "value": "GDPR-32.1" }, { "name": "sort-id", "value": "gdpr-32-01" } ], "parts": [ { "id": "gdpr-art32-1_smt", "name": "statement", "prose": "Den registeransvarige and personuppgiftsbiträdet should, with beaktande of den senaste utvecklingen, throughforandekostnaderna and behandlingens art, scope, sammanhang and ändamål as well as riskerna, of varierande sannolikhetsgrad and allvar, for fysiska personers rättigheter and friheter, throughfora lämpliga technical and organizational åtgärder for to säkerställa en säkerhetsnivå that is lämplig in forhållande to risken, inbegripet pseudonymisering and kryptering of personuppgifter." }, { "id": "gdpr-art32-1_gdn", "name": "guidance", "prose": "for Swedish organizations rekombutderas implementation of kryptering for all persondata både in vila and during overforing. Krypteringsnycklar should is managed according to Swedish säkerhetskrof and preferably through Hardware Security Modules (HSM) or motsvarande säkra nyckelhanteringssystem." } ], "controls": [ { "id": "gdpr-art32-1.1", "title": "Kryptering in vila", "props": [ { "name": "label", "value": "GDPR-32.1.1" } ], "parts": [ { "id": "gdpr-art32-1.1_smt", "name": "statement", "prose": "all databaser and storage systems that innehåller persondata should krypteras in vila with godkända krypteringsalgoritmer." } ] }, { "id": "gdpr-art32-1.2", "title": "Kryptering during overforing", "props": [ { "name": "label", "value": "GDPR-32.1.2" } ], "parts": [ { "id": "gdpr-art32-1.2_smt", "name": "statement", "prose": "All kommuniquetion that overfor persondata should ske over krypterade kanaler with minimum TLS 1.2." } ] } ] } ] }, { "id": "msb-controls", "title": "MSB Säkerhetskrof for Kritisk infrastructure", "props": [ { "name": "label", "value": "MSB" } ], "controls": [ { "id": "msb-3.2.1", "title": "Nätverkssegmentering", "props": [ { "name": "label", "value": "MSB-3.2.1" } ], "parts": [ { "id": "msb-3.2.1_smt", "name": "statement", "prose": "Kritiska system should skyddas through nätverkssegmentering that begränsar potentiell lateral movement of angripare and minimerar attack surface." }, { "id": "msb-3.2.1_gdn", "name": "guidance", "prose": "implementation should inkludera micro-segmentation on application layer, network access control lists and zero-trust network principles. For molnmiljöer rekombutderas implementation through Virtual Private Clouds (VPC), Security Groups and Network Access Control Lists (NACLs)." } ], "controls": [ { "id": "msb-3.2.1.1", "title": "Micro-segmentation", "parts": [ { "id": "msb-3.2.1.1_smt", "name": "statement", "prose": "Applikationer should segmenteras on network layer for to begränsa lateral movement." } ] }, { "id": "msb-3.2.1.2", "title": "Zero Trust Network Access", "parts": [ { "id": "msb-3.2.1.2_smt", "name": "statement", "prose": "all network access requests should verifieras and authoriseras oofsett source location." } ] } ] } ] } ] } } ``` ### OSCAL Profile utveckling for Swedish companies OSCAL Profiles enables Swedish organizations to skapa customized säkerhetskrof that kombinerar múltipla regulatory frameworks in en coherent, implementable standard. This capability is särskilt värdefull for Swedish multinationals that must balansera lokala regulatory requirements with global enterprise standards. ```json { "profile": { "uuid": "87654321-4321-8765-4321-876543218765", "metadata": { "title": "Swedish Finansiella Institutioner Säkerhetsprofil", "published": "2024-01-15T11:00:00Z", "last-modified": "2024-01-15T11:00:00Z", "version": "2.1", "oscal-version": "1.1.2", "props": [ { "name": "organization", "value": "Swedish Finansiella Sektorn" }, { "name": "sector", "value": "Financial Services" } ] }, "imports": [ { "href": "https://raw.githubusercontent.com/usnistgov/oscal-content/main/nist.gov/SP800-53/rev5/json/NIST_SP-800-53_rev5_catalog.json", "include-controls": [ { "matching": [ { "pattern": "ac-.*" }, { "pattern": "au-.*" }, { "pattern": "sc-.*" } ] } ] }, { "href": "Swedish-enterprise-catalog.json", "include-controls": [ { "matching": [ { "pattern": "gdpr-.*" }, { "pattern": "msb-.*" } ] } ] } ], "merge": { "combine": { "method": "merge" } }, "modify": { "set-parameters": [ { "param-id": "ac-1_prm_1", "values": ["Swedish Finansiella security policies"] }, { "param-id": "gdpr-art32-1_prm1", "values": ["AES-256-GCM"] }, { "param-id": "gdpr-art32-1_prm2", "values": ["AWS KMS Customer Managed with HSM backing"] } ], "alters": [ { "control-id": "gdpr-art32-1", "adds": [ { "position": "after", "by-id": "gdpr-art32-1_gdn", "parts": [ { "id": "gdpr-art32-1_fi-gdn", "name": "guidance", "title": "Finansinspektionens toäggskrof", "prose": "Finansiella institutioner should furthermore implement kryptering according to Finansinspektionens foreskrifter om informationssäkerhet (FFFS 2017:7) vilket includes requirements on certified cryptographic modules and regular key rotation." } ] } ] }, { "control-id": "msb-3.2.1", "adds": [ { "position": "after", "by-id": "msb-3.2.1_gdn", "parts": [ { "id": "msb-3.2.1_fi-req", "name": "requirement", "title": "Finansiella toäggskrof", "prose": "Finansiella transaktionssystem should implement additional network isolation and encrypted communication channels for all customer data flows according to PCI DSS Level 1 requirements." } ] } ] } ] } } } ``` ### Component Definition for Infrastructure as Code Architecture as Code-principlesna within This område En of OSCAL:s mest kraftfulla capabilities is möjligheten to dokumentera how specific technology components implementerar säkerhetskontroller. For Infrastructure as Code-practitioners enables This automatic generation of säkerhetsdokumentation and compliance validation directly from infrastructure definitions. ```json { "component-definition": { "uuid": "11223344-5566-7788-99aa-bbccddeeff00", "metadata": { "title": "AWS Infrastructure Components for Swedish organizations", "published": "2024-01-15T12:00:00Z", "last-modified": "2024-01-15T12:00:00Z", "version": "1.5", "oscal-version": "1.1.2" }, "components": [ { "uuid": "comp-aws-rds-mysql", "type": "software", "title": "AWS RDS MySQL Database Instance", "description": "Managed MySQL database service with Swedish compliance configuration", "props": [ { "name": "version", "value": "8.0" }, { "name": "provider", "value": "AWS" } ], "control-implementations": [ { "uuid": "impl-rds-mysql-gdpr", "source": "Swedish-enterprise-catalog.json", "description": "GDPR compliance implementation for RDS MySQL", "implemented-requirements": [ { "uuid": "req-gdpr-encryption", "control-id": "gdpr-art32-1.1", "description": "RDS encryption at rest implementation", "statements": [ { "statement-id": "gdpr-art32-1.1_smt", "uuid": "stmt-rds-encryption", "description": "Encryption konfigurerad through storage_encrypted parameter", "implementation-status": { "state": "implemented" } } ], "props": [ { "name": "implementation-point", "value": "Terraform aws_db_instance resource" } ] }, { "uuid": "req-gdpr-transit-encryption", "control-id": "gdpr-art32-1.2", "description": "RDS encryption in transit implementation", "statements": [ { "statement-id": "gdpr-art32-1.2_smt", "uuid": "stmt-rds-ssl", "description": "TLS enforced through DB parameter groups", "implementation-status": { "state": "implemented" } } ] } ] }, { "uuid": "impl-rds-mysql-msb", "source": "Swedish-enterprise-catalog.json", "description": "MSB compliance implementation for RDS MySQL", "implemented-requirements": [ { "uuid": "req-msb-network-isolation", "control-id": "msb-3.2.1.1", "description": "Network segmentation through VPC and Security Groups", "statements": [ { "statement-id": "msb-3.2.1.1_smt", "uuid": "stmt-rds-vpc", "description": "RDS deployed in private subnets with restricted Security Groups", "implementation-status": { "state": "implemented" } } ] } ] } ] }, { "uuid": "comp-aws-s3-bucket", "type": "software", "title": "AWS S3 Storage Bucket", "description": "Object storage with Swedish compliance and säkerhetskonfiguration", "control-implementations": [ { "uuid": "impl-s3-gdpr", "source": "Swedish-enterprise-catalog.json", "description": "S3 GDPR compliance implementation", "implemented-requirements": [ { "uuid": "req-s3-encryption", "control-id": "gdpr-art32-1.1", "description": "S3 encryption at rest with Customer Managed KMS", "statements": [ { "statement-id": "gdpr-art32-1.1_smt", "uuid": "stmt-s3-kms", "description": "Default encryption configured with AES-256 and Customer Managed KMS keys", "implementation-status": { "state": "implemented" } } ], "props": [ { "name": "encryption-algorithm", "value": "AES-256" }, { "name": "key-management", "value": "AWS KMS Customer Managed" } ] } ] } ] } ] } } ``` ### System Security Plan automation with OSCAL En of OSCAL:s mest transformativa capabilities is möjligheten to automatically generera comprehensive System Security Plans (SSP) from Infrastructure as Code definitions kombinerat with component definitions. This revolutionerar säkerhetsdokumentation from static, manually maintained documents to dynamic, continuously updated representations of actual system state. ```python # Oscal_ssp_generator.py import json import yaml from typing import Dict, List, Any from datetime import datetime import hcl2 import boto3 class OSCALSystemSecurityPlanGenerator: """ Automated generation of OSCAL System Security Plans from Infrastructure as Code """ def __init__(self, terraform_directory: str, component_definitions: List[str]): self.terraform_directory = terraform_directory self.component_definitions = component_definitions self.aws_client = boto3.client('sts') def generate_ssp(self, profile_href: str, system_name: str) -> Dict[str, Any]: """Generera comprehensive SSP from Architecture as Code definitions""" # Parse Terraform configurations terraform_reSources = self._parse_terraform_reSources() # Load component definitions components = self._load_component_definitions() # Match reSources to components resource_mappings = self._map_reSources_to_components(terraform_reSources, components) # Generate control implementations control_implementations = self._generate_control_implementations(resource_mappings) # Create SSP structure ssp = { "system-security-plan": { "uuid": self._generate_uuid(), "metadata": { "title": f"System Security Plan - {system_name}", "published": datetime.now().isoformat() + "Z", "last-modified": datetime.now().isoformat() + "Z", "version": "1.0", "oscal-version": "1.1.2", "props": [ { "name": "organization", "value": "Swedish Enterprise Organization" }, { "name": "system-name", "value": system_name } ] }, "import-profile": { "href": profile_href }, "system-characteristics": { "system-ids": [ { "identifier-type": "https://ietf.org/rfc/rfc4122", "id": self._get_aws_account_id() } ], "system-name": system_name, "description": f"Automated System Security Plan for {system_name} genererad from Infrastructure as Code", "security-sensitivity-level": "moderate", "system-information": { "information-types": [ { "uuid": self._generate_uuid(), "title": "Persondata according to GDPR", "description": "Personuppgifter that treats according to GDPR", "categorizations": [ { "system": "https://doi.org/10.6028/NIST.SP.800-60v1r1", "information-type-ids": ["C.3.5.8"] } ], "confidentiality-impact": { "base": "moderate", "selected": "high", "adjustment-justification": "Swedish GDPR-requirements requires högt skydd" }, "integrity-impact": { "base": "moderate", "selected": "high" }, "ofailability-impact": { "base": "low", "selected": "moderate" } } ] }, "security-impact-level": { "security-objective-confidentiality": "high", "security-objective-integrity": "high", "security-objective-ofailability": "moderate" }, "status": { "state": "operational" }, "authorization-boundary": { "description": "AWS Account boundary inkluderande all Architecture as Code-managed reSources" } }, "system-implementation": { "users": [ { "uuid": self._generate_uuid(), "title": "Swedish System Administrators", "description": "Administratörer with privileged access to system components", "props": [ { "name": "type", "value": "internal" } ], "role-ids": ["admin-role"] }, { "uuid": self._generate_uuid(), "title": "Swedish End Users", "description": "Standard användare with begränsad access", "props": [ { "name": "type", "value": "internal" } ], "role-ids": ["user-role"] } ], "components": self._generate_ssp_components(resource_mappings) }, "control-implementation": { "description": "Control implementation for Swedish compliance requirements", "implemented-requirements": control_implementations } } } return ssp def _parse_terraform_reSources(self) -> List[Dict]: """Parse Terraform configurations and extrahera resource definitions""" reSources = [] for tf_file in self._find_terraform_files(): with open(tf_file, 'r') as f: try: tf_content = hcl2.loads(f.read()) for resource_type, resource_configs in tf_content.get('resource', {}).items(): for resource_name, resource_config in resource_configs.items(): reSources.append({ "type": resource_type, "name": resource_name, "config": resource_config, "file": tf_file }) except Exception as e: print(f"Error parsing {tf_file}: {e}") return reSources def _map_reSources_to_components(self, reSources: List[Dict], components: List[Dict]) -> Dict: """Mappa Terraform reSources to OSCAL components""" mappings = {} for resource in reSources: for component in components: if self._resource_matches_component(resource, component): mappings[f"{resource['type']}.{resource['name']}"] = { "resource": resource, "component": component } return mappings def _resource_matches_component(self, resource: Dict, component: Dict) -> bool: """Kontrollera om en Terraform resource matchar en OSCAL component""" # AWS RDS mapping if resource['type'] == 'aws_db_instance' and 'rds' in component.get('title', '').lower(): return True # AWS S3 mapping if resource['type'] == 'aws_s3_bucket' and 's3' in component.get('title', '').lower(): return True # AWS EC2 mapping if resource['type'] == 'aws_instance' and 'ec2' in component.get('title', '').lower(): return True return False def _generate_control_implementations(self, mappings: Dict) -> List[Dict]: """Generera control implementations baserat on resource mappings""" implementations = [] for resource_id, mapping in mappings.items(): resource = mapping['resource'] component = mapping['component'] for impl in component.get('control-implementations', []): for req in impl.get('implemented-requirements', []): # Validera to resource faktiskt implementerar kontrollen validation_result = self._validate_control_implementation(resource, req) implementations.append({ "uuid": self._generate_uuid(), "control-id": req['control-id'], "description": f"implementation through {resource_id}", "statements": [ { "statement-id": stmt.get('statement-id'), "uuid": self._generate_uuid(), "description": f"{stmt.get('description')} - Status: {validation_result['status']}", "implementation-status": { "state": validation_result['status'] } } for stmt in req.get('statements', []) ], "props": [ { "name": "implementation-point", "value": resource_id }, { "name": "validation-timestamp", "value": datetime.now().isoformat() + "Z" } ] }) return implementations def _validate_control_implementation(self, resource: Dict, requirement: Dict) -> Dict: """Validera to en resource faktiskt implementerar en säkerhetskontroll""" control_id = requirement['control-id'] resource_config = resource['config'] # GDPR encryption validation if 'gdpr-art32-1.1' in control_id: # Encryption at rest if resource['type'] == 'aws_db_instance': encrypted = resource_config.get('storage_encrypted', False) return { "status": "implemented" if encrypted else "planned", "details": f"Storage encryption: {encrypted}" } elif resource['type'] == 'aws_s3_bucket': # Check for server_side_encryption_configuration encryption_config = resource_config.get('server_side_encryption_configuration') return { "status": "implemented" if encryption_config else "planned", "details": f"Encryption configuration present: {bool(encryption_config)}" } # MSB network segmentation validation elif 'msb-3.2.1' in control_id: if resource['type'] == 'aws_db_instance': vpc_sg = resource_config.get('vpc_security_group_ids', []) db_subnet_group = resource_config.get('db_subnet_group_name') return { "status": "implemented" if vpc_sg and db_subnet_group else "planned", "details": f"VPC security: {bool(vpc_sg)}, Subnet group: {bool(db_subnet_group)}" } return {"status": "planned", "details": "Validation not implemented for this kontroll"} def _generate_ssp_components(self, mappings: Dict) -> List[Dict]: """Generera SSP component definitions""" components = [] for resource_id, mapping in mappings.items(): resource = mapping['resource'] component = mapping['component'] components.append({ "uuid": self._generate_uuid(), "type": "software", "title": f"{resource['type']} - {resource['name']}", "description": f"Architecture as Code-managed {resource['type']} implementation", "status": { "state": "operational" }, "props": [ { "name": "terraform-resource", "value": resource_id }, { "name": "deployment-status", "value": "active" } ] }) return components def _generate_uuid(self) -> str: """Generera UUID for OSCAL elements""" import uuid return str(uuid.uuid4()) def _get_aws_account_id(self) -> str: """Hämta AWS account ID for system identification""" try: return self.aws_client.get_caller_identity()['Account'] except Exception: return "unknown-account" def _find_terraform_files(self) -> List[str]: """Hitta all Terraform-filer in directory""" import glob import os tf_files = [] for root, dirs, files in os.walk(self.terraform_directory): for file in files: if file.endswith('.tf'): tf_files.append(os.path.join(root, file)) return tf_files def _load_component_definitions(self) -> List[Dict]: """Ladda OSCAL component definitions""" components = [] for comp_def_file in self.component_definitions: with open(comp_def_file, 'r') as f: comp_def = json.load(f) components.extend(comp_def.get('component-definition', {}).get('components', [])) return components # Användning for Swedish organizations def generate_swedish_enterprise_ssp(): """Exempel on SSP generation for Swedish enterprise-miljö""" generator = OSCALSystemSecurityPlanGenerator( terraform_directory="/path/to/terraform", component_definitions=[ "Swedish-aws-components.json", "kubernetes-components.json" ] ) ssp = generator.generate_ssp( profile_href="Swedish-finansiella-profil.json", system_name="Swedish Enterprise Production Environment" ) # Spara SSP with open("Swedish-enterprise-ssp.json", "w") as f: json.dump(ssp, f, indent=2, ensure_ascii=False) print("System Security Plan genererad for Swedish enterprise-miljö") return ssp ``` ### OSCAL Assessment and Continuous Compliance En of OSCAL:s mest kraftfulla features is möjligheten to automate security assessments and implement continuous compliance monitoring. For Swedish organizations that must demonstrera ongoing compliance with GDPR, MSB-requirements andra regulatoriska frameworks, enables OSCAL assessment automation unprecedented precision and efficiency. ```python # Oscal_assessment_automation.py import json import boto3 from typing import Dict, List, Any from datetime import datetime, tiwithelta import subprocess class OSCALAssessmentEngine: """ Automated OSCAL assessment engine for Swedish compliance requirements """ def __init__(self, ssp_file: str, assessment_plan_file: str): self.ssp_file = ssp_file self.assessment_plan_file = assessment_plan_file self.aws_config = boto3.client('config') self.aws_inspector = boto3.client('inspector2') def execute_assessment(self) -> Dict[str, Any]: """Kör comprehensive OSCAL assessment""" # Ladda SSP and assessment plan with open(self.ssp_file, 'r') as f: ssp = json.load(f) with open(self.assessment_plan_file, 'r') as f: assessment_plan = json.load(f) # Kör automated tests for varje kontroll assessment_results = { "assessment-results": { "uuid": self._generate_uuid(), "metadata": { "title": "Automated OSCAL Assessment - Swedish Enterprise", "published": datetime.now().isoformat() + "Z", "last-modified": datetime.now().isoformat() + "Z", "version": "1.0", "oscal-version": "1.1.2" }, "import-ssp": { "href": self.ssp_file }, "assessment-activities": [], "results": [] } } # Kör assessments for implemented requirements for impl_req in ssp['system-security-plan']['control-implementation']['implemented-requirements']: control_id = impl_req['control-id'] assessment_result = self._assess_control(control_id, impl_req, ssp) assessment_results['assessment-results']['results'].append(assessment_result) # Generera overall compliance score compliance_score = self._calculate_compliance_score(assessment_results['assessment-results']['results']) assessment_results['assessment-results']['compliance-score'] = compliance_score return assessment_results def _assess_control(self, control_id: str, implementation: Dict, ssp: Dict) -> Dict: """Assess en specifik säkerhetskontroll""" if 'gdpr-art32-1' in control_id: return self._assess_gdpr_encryption(control_id, implementation, ssp) elif 'msb-3.2.1' in control_id: return self._assess_msb_network_segmentation(control_id, implementation, ssp) else: return self._assess_generic_control(control_id, implementation) def _assess_gdpr_encryption(self, control_id: str, implementation: Dict, ssp: Dict) -> Dict: """Assess GDPR encryption requirements""" findings = [] # Kontrollera AWS Config rules for encryption compliance config_rules = [ 'rds-storage-encrypted', 's3-bucket-server-side-encryption-enabled', 'ebs-encrypted-volumes' ] for rule_name in config_rules: try: response = self.aws_config.get_compliance_details_by_config_rule( ConfigRuleName=rule_name ) non_compliant_reSources = [ r for r in response.get('EvaluationResults', []) if r['ComplianceType'] == 'NON_COMPLIANT' ] if non_compliant_reSources: findings.append({ "uuid": self._generate_uuid(), "title": f"Non-compliant reSources for {rule_name}", "description": f"Hittade {len(non_compliant_reSources)} non-compliant reSources", "severity": "high", "implementation-statement-uuid": implementation['statements'][0]['uuid'], "related-observations": [ { "observation-uuid": self._generate_uuid(), "description": f"Resource {r['EvaluationResultIdentifier']['EvaluationResultQualifier']['ResourceId']} is non-compliant" } for r in non_compliant_reSources[:5] # Begränsa to 5 for readability ] }) else: findings.append({ "uuid": self._generate_uuid(), "title": f"Compliant encryption for {rule_name}", "description": "all resurser följer encryption requirements", "severity": "info", "implementation-statement-uuid": implementation['statements'][0]['uuid'] }) except Exception as e: findings.append({ "uuid": self._generate_uuid(), "title": f"Assessment error for {rule_name}", "description": f"Kunde not köra assessment: {str(e)}", "severity": "withium" }) # Sammanställ assessment result has_high_findings = any(f.get('severity') == 'high' for f in findings) return { "uuid": self._generate_uuid(), "title": f"GDPR Encryption Assessment - {control_id}", "description": "Automated assessment of GDPR encryption requirements", "start": (datetime.now() - tiwithelta(minutes=5)).isoformat() + "Z", "end": datetime.now().isoformat() + "Z", "props": [ { "name": "assessment-method", "value": "automated" }, { "name": "assessor", "value": "OSCAL Assessment Engine" } ], "findings": findings, "status": "non-compliant" if has_high_findings else "compliant" } def _assess_msb_network_segmentation(self, control_id: str, implementation: Dict, ssp: Dict) -> Dict: """Assess MSB network segmentation requirements""" findings = [] # Kontrollera Security Groups for improper network access ec2_client = boto3.client('ec2') try: security_groups = ec2_client.describe_security_groups()['SecurityGroups'] for sg in security_groups: # Kontrollera for overly permissive ingress rules for rule in sg.get('IpPermissions', []): for ip_range in rule.get('IpRanges', []): if ip_range.get('CidrIp') == '0.0.0.0/0': # Kontrollera om det is administrative ports from_port = rule.get('FromPort', 0) to_port = rule.get('ToPort', 65535) admin_ports = {22, 3389, 5432, 3306, 1433, 27017} if any(port in range(from_port, to_port + 1) for port in admin_ports): findings.append({ "uuid": self._generate_uuid(), "title": "Otoåten administrativ port exponering", "description": f"Security Group {sg['GroupId']} exponerar administrativa portar {from_port}-{to_port} mot internet", "severity": "critical", "target": { "type": "resource", "target-id": sg['GroupId'] } }) # Kontrollera for VPC flow logs flow_logs = ec2_client.describe_flow_logs()['FlowLogs'] active_flow_logs = [fl for fl in flow_logs if fl['FlowLogStatus'] == 'ACTIVE'] if not active_flow_logs: findings.append({ "uuid": self._generate_uuid(), "title": "VPC Flow Logs not aktiverade", "description": "VPC Flow Logs krävs for network monitoring according to MSB-requirements", "severity": "high" }) except Exception as e: findings.append({ "uuid": self._generate_uuid(), "title": "Network assessment error", "description": f"Kunde not köra network assessment: {str(e)}", "severity": "withium" }) has_critical_findings = any(f.get('severity') == 'critical' for f in findings) has_high_findings = any(f.get('severity') == 'high' for f in findings) return { "uuid": self._generate_uuid(), "title": f"MSB Network Segmentation Assessment - {control_id}", "description": "Automated assessment of MSB network segmentation requirements", "start": (datetime.now() - tiwithelta(minutes=3)).isoformat() + "Z", "end": datetime.now().isoformat() + "Z", "findings": findings, "status": "non-compliant" if (has_critical_findings or has_high_findings) else "compliant" } def _assess_generic_control(self, control_id: str, implementation: Dict) -> Dict: """Generic assessment for controls without specific automated tests""" return { "uuid": self._generate_uuid(), "title": f"Manual Assessment Required - {control_id}", "description": "this kontroll requires manual assessment", "start": datetime.now().isoformat() + "Z", "end": datetime.now().isoformat() + "Z", "findings": [ { "uuid": self._generate_uuid(), "title": "Manual review required", "description": f"Control {control_id} requires manual validation of implementation", "severity": "info" } ], "status": "unknown" } def _calculate_compliance_score(self, results: List[Dict]) -> Dict: """Beräkna overall compliance score""" total_controls = len(results) compliant_controls = len([r for r in results if r.get('status') == 'compliant']) non_compliant_controls = len([r for r in results if r.get('status') == 'non-compliant']) unknown_controls = len([r for r in results if r.get('status') == 'unknown']) compliance_percentage = (compliant_controls / total_controls * 100) if total_controls > 0 else 0 return { "overall_percentage": round(compliance_percentage, 1), "total_controls": total_controls, "compliant_controls": compliant_controls, "non_compliant_controls": non_compliant_controls, "unknown_controls": unknown_controls, "assessment_timestamp": datetime.now().isoformat() + "Z" } def _generate_uuid(self) -> str: """Generera UUID for OSCAL elements""" import uuid return str(uuid.uuid4()) # Continuous Compliance Monitoring class OSCALContinuousCompliance: """ Continuous compliance monitoring with OSCAL integration """ def __init__(self, ssp_file: str): self.ssp_file = ssp_file self.assessment_engine = OSCALAssessmentEngine(ssp_file, "assessment-plan.json") def run_daily_compliance_check(self): """Daglig compliance check""" print("Kör daglig OSCAL compliance assessment...") assessment_results = self.assessment_engine.execute_assessment() # Spara results timestamp = datetime.now().strftime("%Y%m%d_%H%M%S") results_file = f"assessment-results-{timestamp}.json" with open(results_file, 'w') as f: json.dump(assessment_results, f, indent=2, ensure_ascii=False) # Analysera results and skicka notifications self._analyze_and_notify(assessment_results) return assessment_results def _analyze_and_notify(self, assessment_results: Dict): """Analysera assessment results and skicka notifications""" compliance_score = assessment_results['assessment-results']['compliance-score'] critical_findings = [] high_findings = [] for result in assessment_results['assessment-results']['results']: for finding in result.get('findings', []): if finding.get('severity') == 'critical': critical_findings.append(finding) elif finding.get('severity') == 'high': high_findings.append(finding) # Notification logic if critical_findings: self._send_critical_alert(critical_findings, compliance_score) elif high_findings: self._send_high_severity_alert(high_findings, compliance_score) elif compliance_score['overall_percentage'] < 95: self._send_compliance_warning(compliance_score) else: self._send_compliance_ok(compliance_score) def _send_critical_alert(self, findings: List[Dict], score: Dict): """Skicka critical security alert""" print(f"🚨 CRITICAL SECURITY ALERT: {len(findings)} critical findings detected!") print(f"Overall compliance: {score['overall_percentage']}%") def _send_high_severity_alert(self, findings: List[Dict], score: Dict): """Skicka high severity alert""" print(f"⚠️ HIGH SEVERITY ALERT: {len(findings)} high severity findings detected!") print(f"Overall compliance: {score['overall_percentage']}%") def _send_compliance_warning(self, score: Dict): """Skicka compliance warning""" print(f"⚠️ COMPLIANCE WARNING: Overall compliance {score['overall_percentage']}% below threshold") def _send_compliance_ok(self, score: Dict): """Skicka compliance OK notification""" print(f"✅ COMPLIANCE OK: Overall compliance {score['overall_percentage']}%") ``` ### OSCAL-integration with CI/CD pipelines for to maximera värdet of OSCAL-implementation must security assessments and compliance validation integreras seamlessly in development workflows. This enables shift-left security practices where säkerhetsproblem upptäcks and addresseras tidigt in utvecklingscykeln. ```yaml # .github/workflows/oscal-compliance-pipeline.yml name: OSCAL Compliance Pipeline on: push: branches: [main, develop] paths: ['infrastructure/**', 'oscal/**'] pull_request: branches: [main] paths: ['infrastructure/**', 'oscal/**'] jobs: oscal-validation: runs-on: ubuntu-latest name: OSCAL Document Validation steps: - uses: actions/checkout@v4 - name: Setup Python uses: actions/setup-python@v4 with: python-version: '3.11' - name: Install OSCAL CLI Tools run: | pip install oscal-tools wget https://github.com/usnistgov/oscal-cli/releases/latest/download/oscal-cli.jar - name: Validate OSCAL Documents run: | # Validera all OSCAL JSON-dokument for file in oscal/*.json; do echo "Validating $file..." jofa -jar oscal-cli.jar validate "$file" done - name: Generate Assessment Plan run: | python scripts/generate_assessment_plan.py \ --profile oscal/Swedish-enterprise-profile.json \ --output oscal/assessment-plan.json infrastructure-compliance: runs-on: ubuntu-latest name: Infrastructure Compliance Assessment needs: oscal-validation steps: - uses: actions/checkout@v4 - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v4 with: aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} aws-region: eu-north-1 - name: Setup Terraform uses: hashicorp/setup-terraform@v3 with: terraform_version: 1.6.0 - name: Terraform Plan working-directory: infrastructure run: | terraform init terraform plan -out=tfplan.binary terraform show -json tfplan.binary > tfplan.json - name: Generate OSCAL SSP run: | python scripts/oscal_ssp_generator.py \ --terraform-dir infrastructure \ --component-definitions oscal/components \ --profile oscal/Swedish-enterprise-profile.json \ --output oscal/system-security-plan.json - name: Run OSCAL Assessment run: | python scripts/oscal_assessment_automation.py \ --ssp oscal/system-security-plan.json \ --assessment-plan oscal/assessment-plan.json \ --output oscal/assessment-results.json - name: Analyze Compliance Results run: | python scripts/analyze_compliance.py \ --results oscal/assessment-results.json \ --threshold 95 \ --output compliance-report.json - name: Upload OSCAL Artifacts uses: actions/upload-artifact@v3 with: name: oscal-artifacts path: | oscal/system-security-plan.json oscal/assessment-results.json compliance-report.json - name: Comment PR with Compliance Results if: github.event_name == 'pull_request' uses: actions/github-script@v6 with: script: | const fs = require('fs'); const complianceReport = JSON.parse(fs.readFileSync('compliance-report.json')); const compliance = complianceReport.compliance_score; const criticalFindings = complianceReport.critical_findings || []; const highFindings = complianceReport.high_findings || []; let statusEmoji = '✅'; let statusText = 'COMPLIANT'; if (criticalFindings.length > 0) { statusEmoji = '🚨'; statusText = 'CRITICAL ISSUES'; } else if (highFindings.length > 0) { statusEmoji = '⚠️'; statusText = 'HIGH SEVERITY ISSUES'; } else if (compliance.overall_percentage < 95) { statusEmoji = '⚠️'; statusText = 'BELOW THRESHOLD'; } const comment = ` ## ${statusEmoji} OSCAL Compliance Assessment **Overall Status:** ${statusText} **Compliance Score:** ${compliance.overall_percentage}% ### Summary - **Total Controls:** ${compliance.total_controls} - **Compliant:** ${compliance.compliant_controls} - **Non-Compliant:** ${compliance.non_compliant_controls} - **Unknown:** ${compliance.unknown_controls} ${criticalFindings.length > 0 ? ` ### 🚨 Critical Findings (${criticalFindings.length}) ${criticalFindings.slice(0, 5).map(f => `- **${f.title}**: ${f.description}`).join('\n')} ${criticalFindings.length > 5 ? `\n*... And ${criticalFindings.length - 5} fler critical findings*` : ''} ` : ''} ${highFindings.length > 0 ? ` ### ⚠️ High Severity Findings (${highFindings.length}) ${highFindings.slice(0, 3).map(f => `- **${f.title}**: ${f.description}`).join('\n')} ${highFindings.length > 3 ? `\n*... And ${highFindings.length - 3} fler high severity findings*` : ''} ` : ''} ### 📋 Regulatory Compliance - **GDPR:** ${complianceReport.regulatory_compliance?.gdpr || 'Unknown'} - **MSB:** ${complianceReport.regulatory_compliance?.msb || 'Unknown'} - **ISO 27001:** ${complianceReport.regulatory_compliance?.iso27001 || 'Unknown'} --- *Assessment perforwith using OSCAL automation at ${new Date().toISOString()}* `; github.rest.issues.createComment({ issue_number: context.issue.number, owner: context.repo.owner, repo: context.repo.repo, body: comment }); - name: Fail on Critical Issues run: | python -c " import json with open('compliance-report.json') as f: report = json.load(f) critical_count = len(report.get('critical_findings', [])) if critical_count > 0: print(f'❌ Found {critical_count} critical security findings. Failing build.') exit(1) else: print('✅ No critical security findings detected.') " continuous-monitoring: runs-on: ubuntu-latest name: Setup Continuous Monitoring if: github.ref == 'refs/heads/main' needs: [infrastructure-compliance] steps: - uses: actions/checkout@v4 - name: Deploy Compliance Monitoring run: | # Deploy CloudWatch dashboard for compliance monitoring aws cloudformation deploy \ --template-file monitoring/oscal-compliance-dashboard.yaml \ --stack-name oscal-compliance-monitoring \ --capabilities CAPABILITY_IAM \ --region eu-north-1 - name: Schedule Daily Assessments run: | # Skapa EventBridge rule for dagliga assessments aws events put-rule \ --name daily-oscal-assessment \ --schedule-expression "cron(0 6 * * ? *)" \ --description "Daily OSCAL compliance assessment" ``` OSCAL representerar framtiden for säkerhetsautomatisering and compliance management within Infrastructure as Code. For Swedish organizations that must balansera regulatory compliance with innovation velocity erbjuder OSCAL en path forward that enables både enhanced security and operational efficiency. ## Gatekeeper and Kubernetes Policy Enforcement: Enterprise-grade implementationer Kubernetes-miljöer representerar en unik utmaning for policy enforcement on grund of deras dynamiska natur and complex orchestration patterns. Gatekeeper, baserat on OPA, hofe framträtt that den ledande lösningen for Kubernetes admission control, enables comprehensive policy enforcement that integreras seamlessly with Kubernetes-native workflows. For Swedish organizations that adopterar containerisering and Kubernetes that central del of sin Infrastructure as Code-strategi, representerar Gatekeeper en critical capability for to säkerställa to security policies enforcement automatically over all deployments, oofsett development team or application complexity. Gatekeeper's admission controller architecture enables policy evaluation at deployment-time, vilket forhindrar non-compliant workloads from to någonsin nå production. This proactive approach is fundamental for Swedish organizations that must demonstrera preventive controls to regulators and maintain continuous compliance. ### Enterprise Constraint Template design Constraint Templates in Gatekeeper fungerar that reusable policy definitions that can konfigureras with parametrar for different environments and use cases. For Swedish enterprise-miljöer requires constraint templates sophisticated logic that can hantera complex regulatory requirements as well asidigt that de ger development teams toräcklig flexibilitet for innovation. ```yaml # Gatekeeper/swedish-enterprise-constraints.yaml apiVersion: templates.gatekeeper.sh/v1beta1 kind: ConstraintTemplate metadata: name: swedishenterprisesecurity annotations: description: "Comprehensive Swedish enterprise säkerhetskrof for Kubernetes workloads" compliance.frameworks: "GDPR,MSB,ISO27001" spec: crd: spec: names: kind: SwedishEnterpriseSecurity validation: openAPIV3Schema: type: object properties: gdprDataClassification: type: object properties: required: type: boolean default: true allowedValues: type: array items: type: string default: ["public", "internal", "confidential", "personal"] resourceLimits: type: object properties: enforceMemoryLimits: type: boolean default: true enforceCPULimits: type: boolean default: true maxMemoryPerContainer: type: string default: "2Gi" maxCPUPerContainer: type: string default: "1000m" networkSecurity: type: object properties: requireNetworkPolicies: type: boolean default: true allowedRegistries: type: array items: type: string prohibitedPorts: type: array items: type: integer default: [22, 23, 135, 445, 1433, 3306, 3389, 5432, 6379, 27017] auditLogging: type: object properties: requireAuditAnnotations: type: boolean default: true requiredAnnotations: type: array items: type: string default: ["se.audit.owner", "se.audit.purpose", "se.audit.dataflow"] targets: - target: admission.k8s.gatekeeper.sh rego: | package swedishenterprisesecurity import rego.v1 # GDPR Data Classification Enforcement violation[{"msg": msg}] { input.review.object.kind in ["Pod", "Deployment", "StatefulSet", "DaemonSet"] input.parameters.gdprDataClassification.required object_meta := get_object_metadata(input.review.object) not object_meta.labels["se.gdpr.dataclassification"] msg := "Workload must ha GDPR dataklassificering label according to Swedish regelverk" } violation[{"msg": msg}] { input.review.object.kind in ["Pod", "Deployment", "StatefulSet", "DaemonSet"] input.parameters.gdprDataClassification.required object_meta := get_object_metadata(input.review.object) classification := object_meta.labels["se.gdpr.dataclassification"] not classification input.parameters.gdprDataClassification.allowedValues msg := sprintf("GDPR dataklassificering '%v' is not toåten. Toåtna värden: %v", [classification, input.parameters.gdprDataClassification.allowedValues]) } # Resource Limits according to Swedish säkerhetspraxis violation[{"msg": msg}] { input.review.object.kind == "Pod" input.parameters.resourceLimits.enforceMemoryLimits container := input.review.object.spec.containers[_] not container.reSources.limits.memory msg := sprintf("Container '%v' must ha memory limits for säker resurshantering", [container.name]) } violation[{"msg": msg}] { input.review.object.kind == "Pod" input.parameters.resourceLimits.enforceCPULimits container := input.review.object.spec.containers[_] not container.reSources.limits.cpu msg := sprintf("Container '%v' must ha CPU limits for säker resurshantering", [container.name]) } # Excessive Resource Usage Prevention violation[{"msg": msg}] { input.review.object.kind == "Pod" container := input.review.object.spec.containers[_] memory_limit := container.reSources.limits.memory memory_limit exceeds_memory_limit(memory_limit, input.parameters.resourceLimits.maxMemoryPerContainer) msg := sprintf("Container '%v' memory limit %v overskrider toåtet maximum %v", [container.name, memory_limit, input.parameters.resourceLimits.maxMemoryPerContainer]) } # Container Security Context Enforcement violation[{"msg": msg}] { input.review.object.kind == "Pod" container := input.review.object.spec.containers[_] not container.securityContext.runAsNonRoot msg := sprintf("Container '%v' must köras that non-root användare according to MSB säkerhetskrof", [container.name]) } violation[{"msg": msg}] { input.review.object.kind == "Pod" container := input.review.object.spec.containers[_] not container.securityContext.readOnlyRootFilesystem msg := sprintf("Container '%v' must använda read-only root filesystem for improved säkerhet", [container.name]) } violation[{"msg": msg}] { input.review.object.kind == "Pod" container := input.review.object.spec.containers[_] container.securityContext.privileged msg := sprintf("Container '%v' får not köras in privileged mode according to säkerhetspolicy", [container.name]) } # Network Security Enforcement violation[{"msg": msg}] { input.review.object.kind == "Pod" container := input.review.object.spec.containers[_] port := container.ports[_] port.containerPort input.parameters.networkSecurity.prohibitedPorts msg := sprintf("Container '%v' forsöker exponera prohibited port %v", [container.name, port.containerPort]) } # Image Registry Validation violation[{"msg": msg}] { input.review.object.kind == "Pod" container := input.review.object.spec.containers[_] image := container.image not allowed_registry(image, input.parameters.networkSecurity.allowedRegistries) msg := sprintf("Container '%v' använder image from otoåten registry: %v", [container.name, image]) } # Audit Annotation Requirements violation[{"msg": msg}] { input.review.object.kind in ["Pod", "Deployment", "StatefulSet", "DaemonSet"] input.parameters.auditLogging.requireAuditAnnotations object_meta := get_object_metadata(input.review.object) required_annotation := input.parameters.auditLogging.requiredAnnotations[_] not object_meta.annotations[required_annotation] msg := sprintf("Workload must ha audit annotation '%v' for compliance tracking", [required_annotation]) } # Service Account Security violation[{"msg": msg}] { input.review.object.kind == "Pod" input.review.object.spec.serviceAccountName == "default" msg := "Pod får not använda default service account - skapa dedicated service account" } violation[{"msg": msg}] { input.review.object.kind == "Pod" input.review.object.spec.automountServiceAccountToken != false not input.review.object.spec.serviceAccountName msg := "Pod must explicit disable automountServiceAccountToken or använda nawith service account" } # Helper functions get_object_metadata(obj) := obj.metadata { obj.kind == "Pod" } get_object_metadata(obj) := obj.spec.template.metadata { obj.kind in ["Deployment", "StatefulSet", "DaemonSet"] } exceeds_memory_limit(actual, max_allowed) { actual_bytes := parse_memory(actual) max_bytes := parse_memory(max_allowed) actual_bytes > max_bytes } parse_memory(mem_str) := bytes { # Simplified memory parsing - production should handle all units endswith(mem_str, "Gi") gb := to_number(trim_suffix(mem_str, "Gi")) bytes := gb * 1024 * 1024 * 1024 } parse_memory(mem_str) := bytes { endswith(mem_str, "Mi") mb := to_number(trim_suffix(mem_str, "Mi")) bytes := mb * 1024 * 1024 } allowed_registry(image, allowed_registries) { registry := allowed_registries[_] startswith(image, registry) } --- # Production Constraint Instance for Swedish enterprise miljöer apiVersion: config.gatekeeper.sh/v1alpha1 kind: SwedishEnterpriseSecurity metadata: name: production-security-policy namespace: gatekeeper-system spec: enforcementAction: deny # Strict enforcement for production match: - apiGroups: [""] kinds: ["Pod"] namespaces: ["production", "staging"] - apiGroups: ["apps"] kinds: ["Deployment", "StatefulSet", "DaemonSet"] namespaces: ["production", "staging"] parameters: gdprDataClassification: required: true allowedValues: ["internal", "confidential", "personal"] resourceLimits: enforceMemoryLimits: true enforceCPULimits: true maxMemoryPerContainer: "8Gi" maxCPUPerContainer: "4000m" networkSecurity: requireNetworkPolicies: true allowedRegistries: - "harbor.company.se/" - "gcr.io/company-project/" - "eu.gcr.io/company-project/" prohibitedPorts: [22, 23, 135, 445, 1433, 3306, 3389, 5432, 6379, 27017] auditLogging: requireAuditAnnotations: true requiredAnnotations: - "se.audit.owner" - "se.audit.purpose" - "se.audit.dataflow" - "se.compliance.framework" --- # Development Environment Constraint (mindre strikt) apiVersion: config.gatekeeper.sh/v1alpha1 kind: SwedishEnterpriseSecurity metadata: name: development-security-policy namespace: gatekeeper-system spec: enforcementAction: warn # Warning mode for development match: - apiGroups: [""] kinds: ["Pod"] namespaces: ["development", "test"] - apiGroups: ["apps"] kinds: ["Deployment", "StatefulSet", "DaemonSet"] namespaces: ["development", "test"] parameters: gdprDataClassification: required: true allowedValues: ["public", "internal", "confidential", "personal"] resourceLimits: enforceMemoryLimits: true enforceCPULimits: false # Mindre strikt for development maxMemoryPerContainer: "16Gi" maxCPUPerContainer: "8000m" networkSecurity: requireNetworkPolicies: false allowedRegistries: - "harbor.company.se/" - "gcr.io/company-project/" - "howeverer.io/" # toåt public images for development prohibitedPorts: [22, 23, 135, 445] # Endast kritiska portar auditLogging: requireAuditAnnotations: false # Optional for development ``` ### Network Policy automation and enforcement Kubernetes Network Policies utgör en fundamental säkerhetskomponent for micro-segmentation, but their manual configuration is error-prone and svår to maintain large-scale environments. Swedish organizations requires automated network policy generation and enforcement that ensures proper network segmentation as well asidigt that den ger development teams flexibility. ```yaml # Gatekeeper/network-policy-constraint.yaml apiVersion: templates.gatekeeper.sh/v1beta1 kind: ConstraintTemplate metadata: name: swedishnetworkpolicyenforcement spec: crd: spec: names: kind: SwedishNetworkPolicyEnforcement validation: openAPIV3Schema: type: object properties: requireNetworkPolicy: type: boolean default: true allowedNamespaces: type: array items: type: string blockedCommunication: type: array items: type: object properties: from: type: string to: type: string targets: - target: admission.k8s.gatekeeper.sh rego: | package swedishnetworkpolicyenforcement import rego.v1 # Kräv NetworkPolicy for all namespaces with känslig data violation[{"msg": msg}] { input.review.object.kind == "Namespace" namespace_name := input.review.object.metadata.name classification := input.review.object.metadata.labels["se.gdpr.dataclassification"] classification in ["confidential", "personal"] input.parameters.requireNetworkPolicy not has_network_policy(namespace_name) msg := sprintf("Namespace '%v' with dataklassificering '%v' must ha NetworkPolicy", [namespace_name, classification]) } # Förhindra workloads in namespaces without NetworkPolicies violation[{"msg": msg}] { input.review.object.kind in ["Pod", "Deployment", "StatefulSet"] namespace_name := input.review.object.metadata.namespace input.parameters.requireNetworkPolicy not namespace_excluded(namespace_name) not has_network_policy(namespace_name) msg := sprintf("Workloads can not deployeras in namespace '%v' without NetworkPolicy", [namespace_name]) } has_network_policy(namespace) { # This would behöva kompletteras with actual NetworkPolicy lookup # for demonstration antar we to namespaces with vissa labels hofe policies data.kubernetes.networkpolicies[namespace] } namespace_excluded(namespace) { excluded_namespaces := {"kube-system", "kube-public", "gatekeeper-system", "monitoring"} namespace in excluded_namespaces } --- # Automated NetworkPolicy generation for Swedish organizations apiVersion: v1 kind: ConfigMap metadata: name: network-policy-templates namespace: gatekeeper-system data: default-deny-all.yaml: | apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: default-deny-all namespace: {{.Namespace}} labels: se.policy.type: "default-deny" se.compliance.framework: "MSB" spec: podSelector: {} policyTypes: - Ingress - Egress allow-same-namespace.yaml: | apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: allow-same-namespace namespace: {{.Namespace}} labels: se.policy.type: "namespace-isolation" spec: podSelector: {} policyTypes: - Ingress - Egress ingress: - from: - namespaceSelector: matchLabels: name: {{.Namespace}} egress: - to: - namespaceSelector: matchLabels: name: {{.Namespace}} allow-dns.yaml: | apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: allow-dns namespace: {{.Namespace}} spec: podSelector: {} policyTypes: - Egress egress: - to: [] ports: - protocol: UDP port: 53 ``` ### Gatekeeper monitoring and observability for Swedish enterprise-miljöer is comprehensive monitoring of policy enforcement critical for både security operations and compliance demonstrering. Gatekeeper must integreras with existing monitoring infrastructure for real-time alerting and audit trail generation. ```yaml # Monitoring/gatekeeper-monitoring.yaml apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: name: gatekeeper-controller-manager namespace: gatekeeper-system labels: app: gatekeeper se.monitoring.team: "security" spec: selector: matchLabels: control-plane: controller-manager gatekeeper.sh/operation: webhook endpoints: - port: metrics interval: 30s path: /metrics --- apiVersion: monitoring.coreos.com/v1 kind: PrometheusRule metadata: name: gatekeeper-security-alerts namespace: gatekeeper-system labels: se.alerting.severity: "critical" spec: groups: - name: gatekeeper.security rules: - alert: GatekeeperPolicyViolationHigh expr: increase(gatekeeper_violations_total[5m]) > 10 for: 2m labels: severity: warning team: security compliance: "GDPR,MSB" annotations: summary: "Hög frekvens of Gatekeeper policy violations" description: "{{ $value }} policy violations de senaste 5 minuterna" runbook_url: "https://wiki.company.se/gatekeeper-violations" - alert: GatekeeperWebhookDown expr: up{job="gatekeeper-webhook"} == 0 for: 1m labels: severity: critical team: security annotations: summary: "Gatekeeper webhook is not togänglig" description: "Gatekeeper admission webhook is ned - security policies enforces not" action: "Kontrollera Gatekeeper controller status owithelbart" - alert: GatekeeperConstraintViolations expr: | increase(gatekeeper_violations_total{ violation_kind="SwedishEnterpriseSecurity" }[10m]) > 5 for: 5m labels: severity: high team: security regulation: "Swedish-compliance" annotations: summary: "Swedish säkerhetskrof violations upptäckta" description: "{{ $value }} violations of Swedish enterprise säkerhetskrof" compliance_impact: "Potentiell GDPR/MSB compliance risk" --- # Grafana Dashboard ConfigMap apiVersion: v1 kind: ConfigMap metadata: name: gatekeeper-dashboard namespace: monitoring data: gatekeeper-security.json: | { "dashboard": { "title": "Gatekeeper Säkerhet and Compliance", "tags": ["security", "compliance", "Swedish"], "panels": [ { "title": "Policy Violations over tid", "type": "graph", "targets": [ { "expr": "rate(gatekeeper_violations_total[5m])", "legendFormat": "{{ violation_kind }} violations/min" } ], "alert": { "conditions": [ { "query": {"params": ["A", "5m", "now"]}, "reducer": {"type": "ofg"}, "evaluator": {"params": [5], "type": "gt"} } ], "executionErrorState": "alerting", "for": "5m", "frequency": "10s", "handler": 1, "name": "Policy Violations Alert", "noDataState": "no_data" } }, { "title": "Compliance Status per Namespace", "type": "table", "targets": [ { "expr": "gatekeeper_compliance_score_by_namespace", "format": "table" } ] }, { "title": "GDPR Dataklassificering Coverage", "type": "pie", "targets": [ { "expr": "count by (dataclassification) (kube_pod_labels{label_se_gdpr_dataclassification!=\"\"})" } ] } ] } } ## Automatiserad Compliance Monitoring and Enterprise Observability Kontinuerlig compliance monitoring utgör ryggraden in moderna Policy as Code-implementationer for Swedish enterprise-miljöer. Effective monitoring går betydligt längre än traditional logging and encompasses real-time policy evaluation, predictive compliance analysis and automated rewithiation capabilities that ensures to organizations maintainar regulatory adherence also när infrastructure evolves rapidly. Swedish organizations möter unique monitoring challenges on grund of strikta regulatory requirements kring data residency, audit trails and incident reporting. GDPR-compliance requires comprehensive logging of all data processing activities, while MSB:s säkerhetskrof for kritisk infrastructure mandatar real-time threat detection and rapid incident response capabilities. Modern compliance monitoring platforms for Infrastructure as Code integrerar multiple data Sources: infrastructure state from cloud providers, policy evaluation results from OPA/Gatekeeper, application logs from containerized workloads, and security events from SIEM systems. This comprehensive observability enables holistic security posture assessment and enables proactive risk management. ### Enterprise Compliance Observability Platform ```python # Monitoring/enterprise_compliance_platform.py import asyncio import json import logging from datetime import datetime, tiwithelta from typing import Dict, List, Any, Optional from dataclasses import dataclass, asdict import boto3 import pandas as pd import plotly.graph_objects as go import plotly.express as px from elasticsearch import Elasticsearch from prometheus_client import CollectorRegistry, Gauge, Counter, push_to_gateway import streamlit as st @dataclass class ComplianceMetric: """Compliance metric representation""" name: str value: float timestamp: datetime framework: str # GDPR, MSB, ISO27001, etc. Severity: str source: str metadata: Dict[str, Any] @dataclass class PolicyViolationEvent: """Policy violation event representation""" id: str timestamp: datetime resource_id: str resource_type: str policy_name: str violation_type: str severity: str message: str regulation_reference: str rewithiation_suggestion: str auto_rewithiable: bool compliance_impact: Dict[str, Any] class EnterpriseCompliancePlatform: """ Comprehensive compliance monitoring platform for Swedish enterprise-miljöer """ def __init__(self, config_file: str = "compliance-platform-config.json"): with open(config_file, 'r') as f: self.config = json.load(f) # Initialize clients self.aws_config = boto3.client('config') self.aws_cloudwatch = boto3.client('cloudwatch') self.aws_cloudtrail = boto3.client('cloudtrail') self.elasticsearch = Elasticsearch(self.config['elasticsearch']['hosts']) # Metrics registry self.metrics_registry = CollectorRegistry() self.setup_metrics() # Logging setup logging.basicConfig(level=logging.INFO) self.logger = logging.getLogger(__name__) def setup_metrics(self): """Setup Prometheus metrics for compliance monitoring""" self.compliance_score_gauge = Gauge( 'compliance_score_by_framework', 'Compliance score per regulatory framework', ['framework', 'environment'], registry=self.metrics_registry ) self.policy_violations_counter = Counter( 'policy_violations_total', 'Total policy violations', ['severity', 'framework', 'resource_type'], registry=self.metrics_registry ) self.rewithiation_success_gauge = Gauge( 'automated_rewithiation_success_rate', 'Success rate for automated rewithiation', ['rewithiation_type'], registry=self.metrics_registry ) async def run_continuous_monitoring(self): """Main loop for continuous compliance monitoring""" self.logger.info("🚀 Starting continuous compliance monitoring...") while True: try: # Parallel execution of monitoring tasks monitoring_tasks = [ self.monitor_aws_config_compliance(), self.monitor_kubernetes_policies(), self.monitor_terraform_state_drift(), self.monitor_data_sovereignty_compliance(), self.analyze_security_posture_trends(), self.check_automated_rewithiation_status() ] results = await asyncio.gather(*monitoring_tasks, return_exceptions=True) # process results and update metrics await self.process_monitoring_results(results) # Update dashboards await self.update_compliance_dashboards() # Check for alerts await self.evaluate_alerting_conditions() # Sleep fore next iteration await asyncio.sleep(self.config['monitoring']['interval_seconds']) except Exception as e: self.logger.error(f"Error in monitoring loop: {e}") await asyncio.sleep(60) # Retry after 1 minute ``` implementation of comprehensive Policy as Code in Swedish enterprise-miljöer requires systematic approach that respekterar existing organizational structures as well asidigt that den introducerar modern automation capabilities. Successful implementations karakteriseras of gradual adoption, strong stakeholder buy-in and careful integration with existing governance frameworks. ### Integration with Swedish säkerhetsmyndigheter for organizations within kritisk infrastructure requires compliance monitoring integration with Swedish säkerhetsmyndigheter and automated incident reporting capabilities. This includes integration with MSB:s incidentrapporteringssystem and automated generation of compliance reports for regulatory authorities. ```python # Integration/swedish_authorities_integration.py import json import asyncio from datetime import datetime from typing import Dict, List import requests from cryptography.fernet import Fernet class SwedishAuthoritiesIntegration: """ Integration with Swedish säkerhetsmyndigheter for compliance reporting """ def __init__(self): self.msb_api_endpoint = "https://api.msb.se/incident-reporting/v2" self.fi_api_endpoint = "https://api.fi.se/compliance-reporting/v1" self.encryption_key = Fernet.generate_key() self.cipher_suite = Fernet(self.encryption_key) async def report_security_incident_to_msb(self, incident_data: Dict) -> Dict: """Report säkerhetsincident to MSB according to MSBFS 2020:6""" # Encrypt sensitive data encrypted_data = self._encrypt_sensitive_data(incident_data) msb_report = { "incident_id": incident_data['id'], "timestamp": datetime.now().isoformat(), "severity": self._map_severity_to_msb_scale(incident_data['severity']), "affected_systems": encrypted_data['systems'], "incident_type": incident_data['type'], "impact_assessment": { "confidentiality": incident_data.get('impact', {}).get('confidentiality', 'unknown'), "integrity": incident_data.get('impact', {}).get('integrity', 'unknown'), "ofailability": incident_data.get('impact', {}).get('ofailability', 'unknown') }, "rewithiation_actions": incident_data.get('rewithiation', []), "lessons_learned": incident_data.get('lessons_learned', ''), "regulatory_compliance": { "gdpr_relevant": incident_data.get('gdpr_impact', False), "personal_data_affected": incident_data.get('personal_data_count', 0) } } try: response = await self._send_to_msb(msb_report) return {"status": "success", "msb_reference": response.get('reference_id')} except Exception as e: return {"status": "error", "message": str(e)} ``` ## Practical implementationsexempel and Swedish organizations implementation of comprehensive Policy as Code in Swedish enterprise-miljöer requires systematic approach that respekterar existing organizational structures as well asidigt that den introducerar modern automation capabilities. Successful implementations karakteriseras of gradual adoption, strong stakeholder buy-in and careful integration with existing governance frameworks. Swedish organizations that hofe successful implementerat Policy as Code hofe typically följt en phased approach: börjat with non-critical environments for experimentation, byggt up policy libraries gradually and establish proven governance processes before rollout to production environments. This approach minimerar risk as well asidigt that den ger teams tid to develop competence and confidence with new tools and processes. ### Implementation roadmap for Swedish organizations **Fas 1: Foundation and Planning (Månader 1-3)** - Stakeholder alignment and executive buy-in - Regulatory requirements mapping (GDPR, MSB, branschspecific requirements) - Technical architecture planning and tool selection - Team training and competence development - Pilot project selection and planning **Fas 2: Pilot implementation (Månader 4-6)** - Non-production environment implementation - Basic policy library development - CI/CD pipeline integration - Monitoring and alerting setup - Initial automation development **Fas 3: Production Rollout (Månader 7-12)** - Production environment deployment - Comprehensive policy coverage - Advanced automation implementation - Integration with existing SIEM/monitoring systems - Compliance reporting automation **Fas 4: Optimization and Scale (Månader 13+)** - Advanced policy analytics - Predictive compliance monitoring - Cross-organization policy sharing - Continuous improvement processes - Advanced automation capabilities ## Sammanfattning and framtidsperspektiv Den moderna Architecture as Code-methodologyen representerar framtiden for infrastrukturhantering in Swedish organizations. Policy as Code representerar en fundamental transformation within Infrastructure as Code that enables automated governance, enhanced security and consistent regulatory compliance. For Swedish organizations erbjuder this approach unprecedented capabilities for to hantera complex compliance landscapes as well asidigt that development velocity maintainas. Integration of OSCAL (Open Security Controls Assessment Language) with traditional Policy as Code approaches skapar powerful synergies that enables standardized security control representation, automated compliance assessment and seamless integration between olika security tools. Swedish organizations that adopterar OSCAL-based approaches positionerar sig for framtida regulatory changes and growing compliance complexity. Successful Policy as Code implementation requires more än technology - det requires organizational commitment, cultural change and systematic approach to governance automation. Swedish organizations that investerar in comprehensive Policy as Code capabilities uppnår significant benefits: reduced manual oversight, faster compliance responses, improved security posture and enhanced ability to demonstrate regulatory adherence. Framtiden for Policy as Code within Swedish organizations karakteriseras of continued evolution toward intelligent automation, predictive compliance analytics and seamless integration with emerging technologies such as artificial intelligence and machine learning. Organizations that etablerar strong Policy as Code foundations idag will vara well-positioned for these future developments. Det continuing utvecklandet of regulatory frameworks, combined with increasing sophistication of cyber threats, gör Policy as Code essential for all Swedish organizations that opererar within regulated industries. Investment in Policy as Code capabilities delivers compounding returns through improved security, reduced compliance costs and enhanced operational efficiency. That we move forward to [chapter 12 om compliance and compliance](12_compliance.md), bygger we vidare on these technical foundations for to explore organizational and processaspekter of comprehensive governance strategy, with particular focus on Swedish regulatory environment and practical implementation guidance. ## Sources and referenser - Open Policy Agent Community. "OPA Policy as Code Architecture as Code best practices." OPA Documentation, 2024. - NIST. "OSCAL - Open Security Controls Assessment Language." NIST Special Publication, 2024. - Kubernetes SIG Security. "Gatekeeper Policy Engine Architecture Guide." CNCF Documentation, 2024. - European Union. "GDPR implementation Guidelines for Cloud Infrastructure." EU Publications, 2024. - Myndigheten for samhällsskydd and beredskap. "MSBFS 2020:6 - Säkerhetskrof for kritisk infrastructure." MSB Föreskrifter, 2024. - HashiCorp. "Terraform Sentinel Policy Framework." HashiCorp Enterprise Documentation, 2024. - Cloud Security Alliance. "Policy as Code implementation Guidelines." CSA Publications, 2024. - ISO/IEC 27001:2022. "Information Security Management Systems - Requirements." International Organization for Standardization, 2024. ## Practical implementationsexempel Verkliga implementationer of Policy as Code requires integration with befintliga utvecklingsverktyg and processes. Through to bygga policy validation in CI/CD pipelines säkerställs to compliance kontrolleras automatically before infrastrukturändringar deployeras to produktion. Enterprise-grade policy management includes policy lifecycle management, version control of policies, and comprehensive audit trails of policy decisions. This enables organizations to demonstrate compliance mot regulators and maintain consistent governance across complex infrastructure environments. ## Sammanfattning Policy as Code representerar kritisk evolution within Infrastructure as Code that enables automated governance, security enforcement and regulatory compliance. Through to treat policies as code can organizations uppnå samma fordelar that Architecture as Code erbjuder: version control, testing, automation and consistency. Swedish organizations that implementerar comprehensive Policy as Code capabilities positionerar sig starkt for future regulatory changes and growing compliance requirements. Investment in policy automation delivers compounding benefits through reduced manual oversight, faster compliance responses and improved security posture. Integration with The next chapters diskussion om [compliance and compliance](14_kapitel13.md) bygger vidare on these technical foundations for to adressera organizational and processaspekter of comprehensive governance strategy. ## Sources and referenser - Open Policy Agent. "Policy as Code Documentation." OPA Community, 2023. - Kubernetes SIG Security. "Gatekeeper Policy Engine." CNCF Projects, 2023. - HashiCorp. "Sentinel Policy Framework." HashiCorp Enterprise, 2023. - NIST. "Security and Privacy Controls for Information Systems." NIST Special Publication 800-53, 2023. - European Union. "General Data Protection Regulation implementation Guide." EU Publications, 2023. - MSB. "Säkerhetskrof for kritisk infrastructure." Myndigheten for samhällsskydd and beredskap, 2023.